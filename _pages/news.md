---
layout: single
read_time: false
comments: false
share: false
author_profile: true
title: <br><br><br><br><br>News
title_separator     : 
name                : 
permalink: /news.html
header:
  overlay_color: "#000"
  overlay_filter: "0.3"
  overlay_image: /assets/images/news.jpg
  caption: "Photo: Cataratas do Iguaçu - Foz do Iguaçu, Brazil"
---

* <span style="color:red">Sep 2022 -</span> Paper "A multimodal hyperlapse method based on video and songs’ emotion alignment" accepted to publication in PRL 2022.
<a href="https://www.sciencedirect.com/journal/pattern-recognition-letters"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>
<a href="https://doi.org/10.1016/j.patrec.2022.08.014"><i class="ai ai-fw ai-doi" aria-hidden="true"></i></a>

* <span style="color:red">Sep 2022 -</span> Paper "A soybean seedlings dataset for soil condition and genotype classification" accepted to publication in SIBGRAPI 2022.
<a href="https://sibgrapi.sbc.org.br/event/sibgrapi2022/"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>

* <span style="color:red">Mar 2022 -</span> Paper "Text-driven video acceleration: A weakly-supervised reinforcement learning method" accepted to publication in TPAMI 2022.
<a href="https://www.computer.org/csdl/journal/tp"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>
<a href="https://doi.org/10.1109/TPAMI.2022.3157198"><i class="ai ai-fw ai-doi" aria-hidden="true"></i></a>

* <span style="color:red">Fev 2022 -</span> Paper "Describing image focused in cognitive and visual details for visually impaired people: An approach to generating inclusive paragraphs” accepted to appear in VISAPP 2022 is now publicly available. 
<a href="http://arxiv.org/abs/2202.05331" title="Link to ArXiv publication"><i class="ai ai-fw ai-arxiv" aria-hidden="true"></i></a>
<a href="https://doi.org/10.5220/0010845700003124"><i class="ai ai-fw ai-doi" aria-hidden="true"></i></a>

* <span style="color:red">Nov 2021 -</span> Paper "Describing image focused in cognitive and visual details for visually impaired people: An approach to generating inclusive paragraphs” accepted to appear in VISAPP 2022.

* <span style="color:red">Aug 2021 -</span> Paper "Evaluating Loss Functions for Illustration Super-Resolution Neural Networks” accepted to appear in WUW@SIBGRAPI 2021.

* <span style="color:red">Oct 2020 -</span>  Honorable mention at the CAPES Thesis Award in the field of Computer Science. <i class="fa fa-star fa-1x" aria-hidden="true"></i>  

* <span style="color:red">Oct 2020 -</span> Code of the paper "A Sparse Sampling-based framework for Semantic Fast-Forward of First-Person Videos" TPAMI 2020, is publicly available now. <a href="https://github.com/verlab/SemanticFastForward_TPAMI_2020"><i class="fa fa-github fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">May 2020 -</span> Paper "A gaze driven fast-forward method for first-person videos" accepted to appear in EPIC@CVPR 2020. <a href="https://eyewear-computing.org/EPIC_CVPR20/"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>

* <span style="color:red">Mar 2020 -</span> Paper "A Sparse Sampling-based framework for Semantic Fast-Forward of First-Person Videos" accepted to publication in TPAMI 2020. <a href="https://www.computer.org/csdl/journal/tp"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>
<a href="https://doi.org/10.1109/TPAMI.2020.2983929"><i class="ai ai-fw ai-doi" aria-hidden="true"></i></a>

* <span style="color:red">Feb 2020 -</span> Paper "Straight to the Point: Fast-forwarding Videos via Reinforcement Learning Using Textual Data" accepted to appear in CVPR 2020. <a href="http://cvpr2020.thecvf.com/"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>

* <span style="color:red">Nov 2019 -</span> Paper "Personalizing Fast-Forward Videos Based on Visual and Textual Features from Social Network" accepted to WACV 2020. <a href="https://wacv20.wacv.net/"> <i class="fa fa-link fa-1x" aria-hidden="true"></i> </a>

* <span style="color:red">Nov 2019 -</span> Best Ph.Dd Thesis Award in the Workshop of Thesis and Dissertation (WTD) Sibgrapi 2019. <a href="http://www.mat.puc-rio.br/sibgrapi2019/"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Oct 2019 -</span> WTD "A Hands-on Tutorial on Fast Forwarding First-Person Videos" presented at Sibgrapi 2019 - Rio de Janeiro (Brazil). <a href="http://www.mat.puc-rio.br/sibgrapi2019/"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a> <a href="https://doi.org/10.5753/sibgrapi.est.2019.8302"><i class="ai ai-fw ai-doi" aria-hidden="true"></i></a>

* <span style="color:red">Oct 2019 -</span> Tutorial "A Hands-on Tutorial on Fast Forwarding First-Person Videos" presented at Sibgrapi 2019. <a href="http://www.mat.puc-rio.br/sibgrapi2019/"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a> <a href="https://github.com/verlab/2019-sibgrapi-hyperlapse/"><i class="fa fa-fw fa-github fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Oct 2019 -</span> Started new job as Lecturer at the Department of Computer Science of Universidade Federal de Lavras (UFLA). <a href="http://ufla.br"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Oct 2019 -</span> My Ph.D. Thesis is now available! <a href="http://hdl.handle.net/1843/30433"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">July 2019 -</span> Ph.D. Thesis Defense. <a href="https://www.verlab.dcc.ufmg.br/phd-thesis-defense-michel-silva/"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Jan 2019 -</span> The paper A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos is official available.<a href="https://doi.org/10.1109/CVPR.2018.00253"><i class="ai ai-doi ia-1x" aria-hidden="true"></i>

* <span style="color:red">Set 2018 -</span> Award on Integration Day of Post-Graduate Program in Computer Science of UFMG event [DIP 2018](http://www.dip.dcc.ufmg.br/) - category: Highlighted Doctoral Dissertation.   <!--<a href="http://www.dcc.ufmg.br/dcc/?q=pt-br/node/3332"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a> --> 

* <span style="color:red">Jun 2018 -</span> Poster presented at [CVPR 2018](http://cvpr2018.thecvf.com/) in Salt Lake City - Utah (USA). <a href="http://www.dcc.ufmg.br/dcc/?q=pt-br/node/3332"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a>  


* <span style="color:red">Apr 2018 -</span> Code of the paper A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos, CVPR 2018 is publicly available now. <a href="https://github.com/verlab/SemanticFastForward_CVPR_2018"><i class="fa fa-github fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Mar 2018 -</span> The DoMSEV is publicly available now. This dataset was proposed in the paper A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos, CVPR 2018. <a href="https://www.verlab.dcc.ufmg.br/semantic-hyperlapse/cvpr2018-dataset/"><i class="fa fa-link fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Mar 2018 -</span> Code of the paper Making a long story short: A Multi-Importance fast-forwarding egocentric videos with the emphasis on relevant objects, JVCI 2018 is publicly available now. <a href="https://github.com/verlab/SemanticFastForward_JVCI_2018"><i class="fa fa-github fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">Fev 2018 -</span> Paper accepted to [JVCI 2018](https://www.journals.elsevier.com/journal-of-visual-communication-and-image-representation) - Making a long story short: A Multi-Importance fast-forwarding egocentric videos with the emphasis on relevant objects. <a href="https://doi.org/10.1016/j.jvcir.2018.02.013"><i class="ai ai-doi ia-1x" aria-hidden="true"></i></a>

* <span style="color:red">Fev 2018 -</span> Paper accepted to [CVPR 2018](http://cvpr2018.thecvf.com/) - A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos.<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Silva_A_Weighted_Sparse_CVPR_2018_paper.pdf"><i class="fa fa-link fa-1x" aria-hidden="true"></i>

* <span style="color:red">Oct 2017 -</span> [ArXiv](https://arxiv.org/) Paper - Making a long story short: A Multi-Importance Semantic for Fast-Forwarding Egocentric Videos. <a href="https://arxiv.org/abs/1711.03473"><i class="ai ai-arxiv fa-1x" aria-hidden="true"></i></a>  

* <span style="color:red">May 2016 -</span> Paper accepted to [EPIC@ECCV 2016](http://www.eyewear-computing.org/EPIC_ECCV16/) - Towards Semantic Fast-Forward and Stabilized Egocentric Videos. <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-46604-0_40"><i class="ai ai-springer ia-1x" aria-hidden="true"></i></a>  

* <span style="color:red">April 2016 -</span> Paper accepted to [ICIP 2016](http://2016.ieeeicip.org/) - Fast-Forward Video Based on Semantic Extraction. <a href="http://ieeexplore.ieee.org/document/7532977/"><i class="ai ai-ieee fa-1x" aria-hidden="true"></i></a>  

## News in the Press  

* <span style="color:red">Sep 2020 -</span> List of the CAPES Thesis Award 2020 winners [Pt-br]. <a href="https://ufmg.br/comunicacao/noticias/divulgada-lista-dos-vencedores-do-premio-capes-de-teses-2020"><i class="fa fa-newspaper-o fa-1x" aria-hidden="true"></i>

* <span style="color:red">Mar 2019 -</span> UFMG researchers create software to improve first-person videos [Pt-br]. <a href="http://www.simi.org.br/noticia/Pesquisadores-da-UFMG-criam-software-para-melhorar-videos-em-primeira-pessoa?fbclid=IwAR0dGcWbII_iF4iDE7DAGX_HW_HVoWUp4frJKhVXw3YrOCgCvox3eva0OOY"><i class="fa fa-newspaper-o fa-1x" aria-hidden="true"></i>

* <span style="color:red">Sep 2018 -</span> DCC researchers presented papers at CVPR 2018, the premier Computer Vision conference in the world [Pt-br]. <a href="http://dcc.ufmg.br/dcc/?q=pt-br/node/3332"><i class="fa fa-newspaper-o fa-1x" aria-hidden="true"></i>
